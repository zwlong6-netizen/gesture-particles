# 基于 Three.js 和 MediaPipe Hands 的实时交互式 3D 粒子系统

**目标：**
创建一个现代化的 React 应用，利用 Three.js 进行 3D 粒子渲染，并通过摄像头捕捉 Google MediaPipe Hands 进行实时手势交互。

**核心功能要求：**

1.  **视觉呈现**：
    *   **全屏摄像头背景**：将摄像头实时视频流作为应用的全屏背景，并进行镜像显示，以便用户习惯。视频画面应略微透明或变暗，以突出前景粒子。
    *   **透明 3D 粒子层**：Three.js 渲染的 3D 粒子系统应以透明背景覆盖在摄像头视频之上。
    *   **粒子文字显示**：粒子能够动态聚合成预设的文字（例如 "HELLO", "FUTURE", "WORLD"）。
    *   **粒子数量**：默认粒子数量应控制在 8000 个左右，以平衡性能和视觉效果。
    *   **文字清晰度**：粒子文字应清晰可辨，默认正对着屏幕，不应有自动旋转，但可以有轻微的呼吸感或摆动以增加生动性。粒子大小和透明度应适当调整，使文字更实。

2.  **手势交互 - 文字切换 (单手)**：
    *   当摄像头检测到一只手时，根据伸出的手指数量（不包含拇指）切换粒子形成的文字。
    *   **1 根手指**：粒子组成文字 "HELLO"。
    *   **2 根手指**：粒子组成文字 "FUTURE"。
    *   **3 根手指**：粒子组成文字 "WORLD"。

3.  **手势交互 - 粒子聚合与回归 (单手)**：
    *   当检测到一只手时，根据手掌的**握拳程度**（Grip Strength）控制粒子形态。
    *   **完全握拳** (`Grip Strength` 接近 1.0，例如 > 0.9)：所有粒子应立即**聚合成一个致密的中央球体**，文字形态消失。
    *   **手掌张开** (`Grip Strength` 小于 0.9)：所有粒子应立即**回归并组成当前的文字形态**。
    *   这是一个**二元开关式**的控制（聚合或文字），而非连续渐变。

4.  **技术栈与依赖**：
    *   React + Vite (用于项目搭建和开发)
    *   Three.js (用于 3D 渲染)
    *   MediaPipe Hands (用于手势识别)
    *   `react-webcam` (用于获取摄像头视频流)
    *   MediaPipe 库（`@mediapipe/hands`, `@mediapipe/camera_utils`）应通过 CDN 引入 `index.html`，以避免打包问题。

5.  **健壮性与用户体验**：
    *   **异步加载处理**：MediaPipe AI 模型加载可能需要时间，应用应显示 "Loading AI Model..." 状态，直到模型完全加载成功。
    *   **手势检测鲁棒性**：手势识别算法（特别是握拳检测）应具有较高的鲁棒性，能够适应不同的手型、光线和摄像头角度。
    *   **调试信息**：在 UI 上显示实时的调试信息，包括：AI 模型加载状态、检测到的手数量、伸出的手指数量、当前的 `Grip Strength` 值以及当前显示的文字，便于用户和开发者理解交互状态。
    *   **性能优化**：确保粒子动画流畅，即使在实时视频背景下也能保持较好的帧率。

**实现细节提示：**
*   **握拳检测**：通过比较指尖到手掌根部（MCP）的距离与手掌大小（例如手腕到中指 MCP 的距离）的比例来判断手指的弯曲程度。
*   **粒子动画**：在 Three.js 的 `animate` 循环中使用 `useRef` 来获取最新的 `interactionFactor` 值，避免闭包问题。粒子目标位置根据手势状态在“文字形态”和“中心聚合形态”之间切换，并使用线性插值平滑过渡。
*   **摄像头流**：`react-webcam` 捕获的视频流应以中等分辨率（如 640x480）传递给 MediaPipe 处理，以平衡识别精度和性能，但显示时可拉伸至全屏。
